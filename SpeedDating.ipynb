{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQJnzLSJCmgX"
      },
      "outputs": [],
      "source": [
        "# Import PyTorch and related packages\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.optim import NAdam, AdamW, Adam, SGD, RMSprop\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
        "\n",
        "# Import packages for data manipulation and data splitting\n",
        "import re\n",
        "from fuzzywuzzy import process, fuzz\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "\n",
        "\n",
        "# Downloading datasets, and loading\n",
        "from sklearn.datasets import fetch_openml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhfNoW68ChxF",
        "outputId": "d99e4820-c705-4569-ecce-af179601882f"
      },
      "outputs": [],
      "source": [
        "# Ensure that floats are displayed with a decimal point\n",
        "pd.options.display.float_format = '{:.1f}'.format\n",
        "\n",
        "# Fetch the 'adult' dataset from OpenML\n",
        "dataset = fetch_openml(name='SpeedDating', version=1)\n",
        "\n",
        "# Create a Pandas DataFrame\n",
        "df = pd.DataFrame(data=np.c_[dataset['data'], dataset['target']],\n",
        "                  columns=dataset['feature_names'] + ['target'])\n",
        "\n",
        "# Display the first few rows\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7C43JDAExqx",
        "outputId": "8e61dda4-2abe-4c53-c681-e0d469dba5ea"
      },
      "outputs": [],
      "source": [
        "def print_unique_for_column(df, column):\n",
        "    unique_values = df[column].unique()\n",
        "    sum = df[column].nunique(dropna=False)\n",
        "    print(f\"Unique values in column '{column}' with sum of {sum} (including NaN): {unique_values}\")\n",
        "\n",
        "def print_unique(df=df):\n",
        "    # Loop through each column and print unique values\n",
        "    for column in df.columns:\n",
        "        print_unique_for_column(df, column)\n",
        "\n",
        "print_unique(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Column field has a lot of problems\n",
        "print(f\"Sum: {df['field'].nunique(dropna=True)}\")\n",
        "sorted_unique_values = sorted(df['field'].dropna().unique())\n",
        "for value in sorted_unique_values:\n",
        "    print(value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3vxhtV7F9Dz"
      },
      "outputs": [],
      "source": [
        "# Regular expression to match ;, :, -, /, and everything within []\n",
        "pattern = r'[;:\\-\\/]|\\[.*?\\]'\n",
        "\n",
        "# Replace matched patterns with an empty string\n",
        "df['field'] = df['field'].str.replace(pattern, ' ', regex=True)\n",
        "\n",
        "# Remove phd and remove duplicate space\n",
        "df['field'] = df['field'].str.replace('phd', '', flags=re.IGNORECASE, regex=True).str.replace(' +', ' ', regex=True)\n",
        "\n",
        "# Replace shortened engg. with engineering\n",
        "df['field'] = df['field'].str.replace('engg.', 'engineering', flags=re.IGNORECASE, regex=True)\n",
        "\n",
        "# Change everything to lowercase and remove white space\n",
        "df['field'] = df['field'].str.lower().str.strip()\n",
        "df['race'] = df['race'].str.lower().str.strip()\n",
        "df['race_o'] = df['race_o'].str.lower().str.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a function to replace close matches\n",
        "def combine_similar(df, column, correct_value, threshold=90):\n",
        "    # Get unique values\n",
        "    unique_values = df[column].unique()\n",
        "    \n",
        "    # Find matches above the threshold\n",
        "    matches = process.extract(correct_value, unique_values, limit=None, scorer=fuzz.token_sort_ratio)\n",
        "    close_matches = [match[0] for match in matches if match[1] >= threshold]\n",
        "    \n",
        "    # Replace close matches with the correct value\n",
        "    df[column] = df[column].apply(lambda x: correct_value if x in close_matches else x)\n",
        "\n",
        "combine_similar(df, 'field', 'finance')\n",
        "combine_similar(df, 'field', 'nutrition')\n",
        "combine_similar(df, 'field', 'speech language pathology')\n",
        "combine_similar(df, 'field', 'international affairs')\n",
        "combine_similar(df, 'field', 'finance economics')\n",
        "combine_similar(df, 'field', 'mathematic')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BW58FGbXM1Wo",
        "outputId": "98b7430a-8cdd-4e7c-cc26-f6c018c5edc5"
      },
      "outputs": [],
      "source": [
        "# Dropped from 259 to 203 nut including NaN\n",
        "print(f\"Sum: {df['field'].nunique(dropna=True)}\")\n",
        "sorted_unique_values = sorted(df['field'].dropna().unique())\n",
        "for value in sorted_unique_values:\n",
        "    print(value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def try_convert_float(value):\n",
        "    try:\n",
        "        return float(value)\n",
        "    except ValueError:\n",
        "        return value\n",
        "\n",
        "for column in df.columns:\n",
        "  df[column] = df[column].apply(try_convert_float)\n",
        "\n",
        "print_unique(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Filling the NaN values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check how much of percentage is missing from every column\n",
        "missing_values = (df.isnull().sum() / len(df)) * 100\n",
        "\n",
        "for name, value in missing_values.items():\n",
        "  print(f\"{name}: {value:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "columns_to_drop = ['has_null', 'wave', 'target']\n",
        "df_features = df.drop(columns=columns_to_drop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This will select columns with data type 'object' or 'string'\n",
        "string_columns = df.select_dtypes(include=['object', 'string'])\n",
        "\n",
        "# Now, print these columns\n",
        "print_unique(string_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nominal_columns = ['gender', 'race', 'race_o', 'field']\n",
        "ordinal_columns = string_columns.drop(columns=nominal_columns)\n",
        "\n",
        "# Encode with one hot encoder\n",
        "df_encoded = pd.get_dummies(df_features, columns=nominal_columns, drop_first=False)\n",
        "\n",
        "# Encode with ordinal encoder\n",
        "\n",
        "# Define the order of categories\n",
        "order = {'[0-1]': 0.0, '[2-3]': 1.0, '[4-6]': 2.0, '[7-37]': 3.0,\n",
        "         '[0-1]': 0.0, '[2-5]': 1.0, '[6-10]': 2.0,\n",
        "         '[0-2]': 0.0, '[3-5]': 1.0, '[5-18]': 2.0,\n",
        "         '[0-3]': 0.0, '[4-9]': 1.0, '[10-20]': 2.0,\n",
        "         '[0-4]': 0.0, '[5-6]': 1.0, '[7-10]': 2.0,\n",
        "         '[0-5]': 0.0, '[6-8]': 1.0, '[9-10]': 2.0, \n",
        "         '[0-15]': 0.0, '[16-20]': 1.0, '[21-100]': 2.0,\n",
        "         '[-1-0]': 0.0, '[0-0.33]': 1.0, '[0.33-1]' : 2.0}\n",
        "\n",
        "# Encode the data\n",
        "for column in ordinal_columns:\n",
        "    df_encoded[column] = df_encoded[column].map(order)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print_unique(df_encoded.select_dtypes(include=['object', 'string']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "df_scaled = scaler.fit_transform(df_encoded)\n",
        "df_scaled = pd.DataFrame(df_scaled, columns=df_encoded.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the KNNImputer\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "\n",
        "# Fit the imputer to your data and transform it\n",
        "imputed_data = imputer.fit_transform(df_scaled)\n",
        "\n",
        "clean_data = pd.DataFrame(imputed_data, columns=df_encoded.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = clean_data\n",
        "y = df['target']\n",
        "\n",
        "mic = mutual_info_classif(X, y)\n",
        "\n",
        "mic_series = pd.Series(mic, index=X.columns)\n",
        "mic_series = mic_series.sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mic_series = mic_series[mic_series > 0.01]\n",
        "\n",
        "mic_series.plot.bar(figsize=(15, 4))\n",
        "plt.ylabel('Mutual Information Score')\n",
        "plt.xlabel('Features')\n",
        "plt.title('Mutual Information Scores')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_data = clean_data[mic_series.index.tolist()]\n",
        "target_date = df['target']"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
